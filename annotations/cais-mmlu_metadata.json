{
  "@context": {
    "@language": "en",
    "@vocab": "https://schema.org/",
    "citeAs": "cr:citeAs",
    "column": "cr:column",
    "conformsTo": "dct:conformsTo",
    "cr": "http://mlcommons.org/croissant/",
    "rai": "http://mlcommons.org/croissant/RAI/",
    "data": {
      "@id": "cr:data",
      "@type": "@json"
    },
    "dataType": {
      "@id": "cr:dataType",
      "@type": "@vocab"
    },
    "dct": "http://purl.org/dc/terms/",
    "examples": {
      "@id": "cr:examples",
      "@type": "@json"
    },
    "extract": "cr:extract",
    "field": "cr:field",
    "fileProperty": "cr:fileProperty",
    "fileObject": "cr:fileObject",
    "fileSet": "cr:fileSet",
    "format": "cr:format",
    "includes": "cr:includes",
    "isLiveDataset": "cr:isLiveDataset",
    "jsonPath": "cr:jsonPath",
    "key": "cr:key",
    "md5": "cr:md5",
    "parentField": "cr:parentField",
    "path": "cr:path",
    "recordSet": "cr:recordSet",
    "references": "cr:references",
    "regex": "cr:regex",
    "repeated": "cr:repeated",
    "replace": "cr:replace",
    "sc": "https://schema.org/",
    "separator": "cr:separator",
    "source": "cr:source",
    "subField": "cr:subField",
    "transform": "cr:transform"
  },
  "@type": "sc:Dataset",
  "name": "cais/mmlu",
  "description": "The MMLU dataset, introduced by Dan Hendrycks, Collin Burns, and others at ICLR 2021, is a massive multitask test that pushes the boundaries of language understanding. With questions spanning subjects from the humanities, social sciences, hard sciences, and other areas, this dataset provides a comprehensive evaluation of a model's ability to understand and reason about complex, real-world information.",
  "conformsTo": "http://mlcommons.org/croissant/1.0",
  "citeAs": "@article{hendryckstest2021,       title={Measuring Massive Multitask Language Understanding},       author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},       journal={Proceedings of the International Conference on Learning Representations (ICLR)},       year={2021}     }",
  "creator": "cais",
  "dateCreated": "2022-03-02",
  "dateModified": "2024-03-08",
  "datePublished": "2022-03-02",
  "inLanguage": "en",
  "keywords": "multiple-choice-qa, Multitask Learning, Language Understanding",
  "license": "mit",
  "url": "https://huggingface.co/datasets/cais/mmlu",
  "task": "abstract_algebra, anatomy, astronomy, business_ethics, clinical_knowledge, college_biology, college_chemistry, college_computer_science, college_mathematics, college_medicine, college_physics, computer_security, conceptual_physics, econometrics, electrical_engineering, elementary_mathematics, formal_logic, global_facts, high_school_biology, high_school_chemistry, high_school_computer_science, high_school_european_history, high_school_geography, high_school_government_and_politics, high_school_macroeconomics, high_school_mathematics, high_school_microeconomics, high_school_physics, high_school_psychology, high_school_statistics, high_school_us_history, high_school_world_history, human_aging, human_sexuality, international_law, jurisprudence, logical_fallacies, machine_learning, management, marketing, medical_genetics, miscellaneous, moral_disputes, moral_scenarios, nutrition, philosophy, prehistory, professional_accounting, professional_law, professional_medicine, professional_psychology, public_relations, question-answering, security_studies, sociology, us_foreign_policy, virology, world_religions",
  "modality": "text"
}