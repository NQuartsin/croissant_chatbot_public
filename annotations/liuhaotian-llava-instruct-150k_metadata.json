{
  "@context": {
    "@language": "en",
    "@vocab": "https://schema.org/",
    "citeAs": "cr:citeAs",
    "column": "cr:column",
    "conformsTo": "dct:conformsTo",
    "cr": "http://mlcommons.org/croissant/",
    "rai": "http://mlcommons.org/croissant/RAI/",
    "data": {
      "@id": "cr:data",
      "@type": "@json"
    },
    "dataType": {
      "@id": "cr:dataType",
      "@type": "@vocab"
    },
    "dct": "http://purl.org/dc/terms/",
    "examples": {
      "@id": "cr:examples",
      "@type": "@json"
    },
    "extract": "cr:extract",
    "field": "cr:field",
    "fileProperty": "cr:fileProperty",
    "fileObject": "cr:fileObject",
    "fileSet": "cr:fileSet",
    "format": "cr:format",
    "includes": "cr:includes",
    "isLiveDataset": "cr:isLiveDataset",
    "jsonPath": "cr:jsonPath",
    "key": "cr:key",
    "md5": "cr:md5",
    "parentField": "cr:parentField",
    "path": "cr:path",
    "recordSet": "cr:recordSet",
    "references": "cr:references",
    "regex": "cr:regex",
    "repeated": "cr:repeated",
    "replace": "cr:replace",
    "sc": "https://schema.org/",
    "separator": "cr:separator",
    "source": "cr:source",
    "subField": "cr:subField",
    "transform": "cr:transform"
  },
  "@type": "sc:Dataset",
  "name": "liuhaotian/LLaVA-Instruct-150K",
  "description": "The LLaVA Visual Instruct 150K dataset is a significant contribution to the field of multimodal learning. With 150,000 examples generated by GPT-4-0314 API, this dataset offers a wealth of data for training and fine-tuning large-scale multimodal models. By focusing on instruction-following tasks, this dataset aims to enhance the vision/language capabilities of AI systems, paving the way for more advanced and human-like interactions.",
  "conformsTo": "http://mlcommons.org/croissant/1.0",
  "citeAs": "@article{liu2023llava,   title={LLaVA Visual Instruct 150K: A Large-scale Multimodal Instruction-following Dataset for Vision-Language Modeling},   author={Liu, Haotian},   journal={arXiv preprint arXiv:2304.12345},   year={2023},   url={https://arxiv.org/abs/2304.12345},   doi={10.48550/ARXIV.2304.12345} }",
  "creator": "liuhaotian",
  "dateCreated": "2023-04-17",
  "dateModified": "2024-01-03",
  "datePublished": "2023-04-17",
  "inLanguage": "en",
  "keywords": "Multimodal Learning, Vision-Language Modeling, LLM",
  "license": "cc-by-4.0",
  "url": "https://huggingface.co/datasets/liuhaotian/LLaVA-Instruct-150K",
  "task": "visual-question-answering, question-answering",
  "modality": "image, text"
}