{
  "name": "HuggingFaceTB/finemath",
  "creators": "HuggingFaceTB",
  "description": "\n\t\n\t\t\n\t\t\ud83d\udcd0 FineMath\n\t\n\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\n\ud83d\udcd0 FineMath consists of 34B tokens (FineMath-3+) and 54B tokens (FineMath-3+ with InfiMM-WebMath-3+) of mathematical educational content filtered from CommonCrawl. To curate this dataset, we trained a mathematical content classifier using annotations generated by LLama-3.1-70B-Instruct. We used the classifier to retain only the most educational mathematics content, focusing on clear explanations and step-by-step problem solving rather than\u2026 See the full description on the dataset page: https://huggingface.co/datasets/HuggingFaceTB/finemath.",
  "license": "odc-by",
  "url": "",
  "publisher": "",
  "version": "",
  "keywords": "",
  "date_modified": "",
  "date_created": "",
  "date_published": "",
  "cite_as": "@misc{allal2025smollm2smolgoesbig, \n      title={SmolLM2: When Smol Goes Big -- Data-Centric Training of a Small Language Model},  \n      author={Loubna Ben Allal and Anton Lozhkov and Elie Bakouch and Gabriel Martín Blázquez and Guilherme Penedo and Lewis Tunstall and Andrés Marafioti and Hynek Kydlíček and Agustín Piqueres Lajarín and Vaibhav Srivastav and Joshua Lochner and Caleb Fahlgren and Xuan-Son Nguyen and Clémentine Fourrier and Ben Burtenshaw and Hugo Larcher and Haojun Zhao and Cyril Zakka and Mathieu Morlon and Colin Raffel and Leandro von Werra and Thomas Wolf}, \n      year={2025}, \n      eprint={2502.02737}, \n      archivePrefix={arXiv}, \n      primaryClass={cs.CL}, \n      url={https://arxiv.org/abs/2502.02737},  \n}",
  "task": "",
  "modality": "tabular, text",
  "in_language": ""
}